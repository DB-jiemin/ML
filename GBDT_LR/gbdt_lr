将原始特征输入到GBDT中,用样本x遍历GBDT树(有很多树),x样本分别落在每棵树的叶子节点上,每个叶子节点对应LR的一维特征,通过遍历所有树,就得到了该样本的所有LR特征.

关键点:
    1.采用ensemble决策树而非单棵决策树
        一棵树表达能力弱,不能表达多个有区分性的特征,多棵树的表达能力强一点.因为每棵树都是在学习前面树的不足.
    2.采用GBDT创建决策树,不用RF(Random Forests)
        GBDT特征分裂主要体现对多数样本有区分度的特征,后面的树,主要体现经过前N颗树,残差仍然较大的少数样本.
	优先选用在整体上有区分度的特征,在选用针对少数样本有区分度的特征.
