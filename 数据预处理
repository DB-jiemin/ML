数据预处理
    1.数据清洗 data cleaning:消除数据中所存在的噪声以及纠正其不一致的错误
          处理:1.填补遗漏的数据值
	       2.平滑噪声数据
	       3.识别或去除异常值
	       4.解决不一致问题
	  遗漏数据处理:例如:分析一个商场销售数据时,发现有多个记录中的属性值为空,如:顾客的收入属性,对于空的属性值,可以采用以下方法进行遗漏数据处理
	       1.忽略该条记录,当label属性遗漏时,应该忽略该记录,但是当每个属性遗漏值的记录比例相差较大时,这种方法不行
	       2.手工填补遗漏值,相对耗时
	       3.利用缺省值填补遗漏值,对一个属性的所有遗漏值均利用一个事先确定好的值来填补,如:利用ok来填补,如果一个属性的遗漏值较多,采用这种方法,则可能误导挖掘过程,虽然简单,但不推荐使用
	       4.利用均值填补遗漏值,计算一个属性的平均值,并用平均值填补该属性所有遗漏值.如:若一个顾客的平均收入为12000,则用此值填补income属性中被遗漏的值.
	       5.利用同类别均值填补遗漏值,这种方法尤其在分类挖掘时使用,如:若要对商场顾客按信用风险(credit_rist)进行分类时,就可以用在同一信用风险类别下的income属性的平均值,来填补所有在同一信用风险类别下属性income的遗漏值.
	       6.利用最可能的值填补遗漏值,可以利用回归分析 贝叶斯公式或决策树推断出该记录特定属性的最大可能的取值.例如:利用数据集中其他顾客的属性值,可以构造一个决策树来预测属性income的遗漏值.(常用)
	  噪声数据处理:被测量变量的一个随机错误和变化.
	       分箱操作,按照属性值进行排序,然后分成大小相等的bin箱
	       1.Bin方法,Bin方法通过利用相应被平滑数据点的周围点,对一组排序数据进行平滑.可以使用bin均值替换bin中所有的值;bin边界平滑,利用bin最大值 或 最小值替换bin中的值,bin的宽度越宽,平滑效果越明显.
	       2.聚类方法,通过聚类可以发现异常数据.
	       3.人机结合检查方法,如:利用基于信息论方法
               4.回归方法,可以利用拟合函数对数据进行平滑.如:借助线性回归方法,包括多变量回归方法,可以获得一个多个变量之间的一个拟合关系,从而达到利用一个变量值来帮助预测另一个变量取值的目的
    2.数据集成 data integration:将来自多个数据源的数据合并到一起构成一个完整的数据集
          处理:消除数据冗余
    3.数据转换 data transformation:将一种格式的数据转换为另一种格式的数据
          处理:对数据进行规格化操作,在正式进行数据挖掘之前,尤其是使用基于对象距离的挖掘算法时,如:nn,最近邻分类等,必须进行数据规格化.也就是将数据压缩至特定的范围内,[0,1]
	       1.平滑处理,帮助除去数据中的噪声,主要技术有:bin方法,聚类方法和回归方法.
	       2.合计处理,对数据进行总结和合计操作,如:每天销售额可以进行合计操作以获得每月或每年的总额.
	       3.数据泛化处理,用更抽象的概念来取代低层次或数据层的数据对象.例如:街道属性,可以泛化到国家 城市的概念.如年龄,可以映射到,年轻 中年 老年.
               4.规格化,将有关属性数据按比例投射到特定范围内,如将工资收入属性映射到(-1,1)
	           1.最大最小规格化
		   2.零均值规格化
		   3.十基数变换规格化
	       5.构造属性,根据已有属性,构造新的属性.
	           例如:利用高 宽可以构造一个新属性面积
    4.数据消减 data reduction:删除冗余特征或聚类消除多于数据
          处理:1.数据聚合,如:构造数据立方
	       2.消减维数,如:通过相关分析消除多余属性
	           1.逐步添加方法
		   2.逐步消减方法
		   3.消减与添加结合方法
		   4.决策树归纳方法
	       3.数据压缩,如:利用编码方法(如,最小编码长度或小波)
	           1.小波分析
		   2.PCA
	       4.数据块消减,如:利用聚类或参数模型替代原有数据
	           1.回归与线性对数模型
		   2.直方图,利用bin方法对数据分布情况进行近似,它是一种常用的数据消减方法.
		       1.等宽方法,在一个等宽的直方图中,每个bucket的宽度是相同的
		       2.等高方法,在一个等高的直方图中,每个bucket的数据个数是相同的
		       3.V-Optimal方法,若对指定bucket个数的所有可能直方图进行考虑,V-Optimal方法所获得的直方图就这些直方图变化最小.直方图变化最小指每个bucket所代表数值的加权之和,其权值为相应bucket的数据个数.
		       4.MaxDiff方法,以相邻数值只差为基础,一个bucket的边界则是由包含由b-1个最大差距的数值对所确定,其中的b为用户指定的阈值.
		   3.聚类,将数据行视为对象,对于聚类分析所获得的组或类则有性质:同一组或类中的对象彼此相似而不同组或类中的对象彼此不相似.相似是利用多维空间中的距离表示.一个组或类的质量可以用其所含对象间的最大距离来衡量;也可以利用中心距离,即以组或类中各对象与中心点距离的平均值,来作为组或类的质量.数据的聚类表示用于替换原有的数据.
		   4.采样,利用一小部分子集来代表一个大的数据集,从而可以作为数据消减的一个技术方法.
		       1.无替换简单随机采样方法,该方法从N个数据行中随机抽取出n哥数据行,以构成由n个数据行组成采样数据子集.
		       2.有替换简单随机采样方法,有放回采样
		       3.聚类采样方法,首先将大数据集D划分为M个不想交的"类",然后从这M个类中的数据对象分别进行随机抽取,这样可以最后获得聚类采样数据子集.
		       3.分层采样方法,首先将大数据集D划分为若干不想交的层,然后在分别从这些层中随机抽取数据对象,从而获得具有代表性的采样数据子集.例如:可以对一个客户数据集按照年龄进行分层,然后在每个年龄组中进行随机选择,从而确保了最终获得分层采样数据子集中的年龄分布具有代表性.
		       利用采样方法进行数据消减的一个突出优点:这样获取样本的时间仅与样本规模成正比.
		       
--------------------------------------------------------------------------
离散化和概念层次树生成
    离散化技术方法可以通过将属性域值范围分为若干区间,来帮助消减一个连续属性的取值个数.可以利用一个标签来表示一个区间内的实际数据值.
    数值概念层次树生成
        1.bin方法
	2.直方图方法
	3.聚类分析方法,按照类型信息对数行进行聚类,然后进行离散化
	4.基于熵的离散化方法,按照label提供的信息计算entrpy,进行离散化
	5.自然划分分段方法
    类别概念层次树生成
        1.属性值的顺序关系已在用户或专家指定的模式定义说明.
	2.通过数据聚合来描述层次树.
	3.定义一组属性但不说明其顺序.
