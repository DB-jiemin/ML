============================================
如何做到下列几点:
    1.分层抽样
    2.特征工程
        1)特征选择 皮尔逊相关系数 基尼指数 信息增益 主要是计算特征与label的相关系数 挑选特征子集,从而达到降维的效果.
	    1:产生过程 搜索特征子集的过程,负责为评价函数提供特征子集
	    2:评价函数 评价一个特征子集好坏程度的一个准则
	    3:停止准则 与评价函数相关,一般是一个阈值,当评价函数值达到这个阈值后就可以停止搜索.
	    4:验证过程 在验证数据集dev上验证选取出来的特征子集的有效性
        2)特征提取 原则上应该在特征选择之前.特征提取的对象是原始数据(raw data).
	    PCA
	    LCA
	    LDA
        3)特征构建 从原始数据中人工的构建新特征,一般可以使用混合属性或者组合属性来创建新的特征,或分解切分原有的特征来创建新的特征
        4)特征工程处理过程
	    1.选择数据:整合数据,将数据规范化成一个数据集,收集起来
	    2.数据预处理:数据格式化,数据清理,采样等
	    3.数据转换:这个阶段做特征工程
	    4.数据建模:建立模型,评估模型并逐步优化
	    特征工程是一个迭代的过程,需要不断的设计特征 选择特征 建立模型 评估模型,最后才能得到最终的model.
	    特征工程迭代过程:
	        1.头脑风暴式特征:尽可能的从原始数据中提取特征,暂时不考虑其重要性
		2.设计特征:根据问题,可以使用自动的特征提取,或是手工构造特征,或者两者混用
		3.特征选择:使用不同的特征重要性评分和特征选择方法进行特征选择
		4.评估模型:使用你选择的特征进行建模,同时使用未知的数据来评估模型
        例如:有一个color特征,取值为red blue unknown,可以构建一个二值特征has_color取值1或者0,1表示有颜色,0表示没有颜色.或者可以将其转换成三个特征,is_red is_blue is_unknown,这样可以使用线性的模型进行处理.
	例如:时间型特征该如何处理?比如想知道某一天的时间段和其他属性的关系,可以创建一个数字特征 Hour_of_day
                                  或者创建一个叙述特征part_of_day,取值为morning midday afternoon night
				  还可以使用春夏秋冬
				  还可以使用距离现在多少天
				  星期  月份 等等都是构建特征的方法
        conclusion:
	    特征工程:利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征过程
	    特征构建:原始数据中人工的构建新特征
            特征提取:自动的构建新的特征,将原始特征转换为一组具有明显物理意义或者统计意义 或 核的特征
	    特征选择:从特征集合中挑选一组最具有统计意义的特征子集,从而达到降维的效果
            -------------------------
	    特征构建 > 特征提取 > 特征选择
            -------------------------
    3.类不平衡怎么处理  postive only learning
    4.数据清洗   特征提取
    5.如何清除离群点 可以用过cv然后确定哪个k fold与其他的有较大的差别,可能该flod包含outlier,清除即可
============================================
分裂数据集为train dev test .6 .2 .2比例进行分配
   或者分配 train  test  做交叉验证
模型选择
cv  交叉验证是用来找到最好超参数
训练
dev
测试
调参
============================================
数据采样:
    大多数模型对数据的正负样本比例敏感 例如LR
    随机采样 或 分层抽样
        分层抽样:例如：某校抽样调查初中学生读课外书的情况，全校共有学生485人，其中一年级180人，二年级160人，三年级145人，如果从全校学生中抽取100人进行调查，那么不同年级可视为不同层次，按每个年级的人数比例抽样。三个年级学生人数占全校总人数的比例分别为37%。33%，30%，则每年级抽取的人数分别为37（即100*37%）人，33人，30人，每个年级的学生可再通过简单随机抽样或机械抽样的方法确定。
	例如，一个单位的职工有500人，其中不到35岁有125人，35岁至49岁的有280人，50岁以上的有95人.为了了解这个单位职工与身体状况有关的某项指标，要从中抽取一个容量为100的样本，由于职工年龄与这项指标有关，决定采用分层抽样方法进行抽取.因为样本容量与总体的个数的比为1：5，所以在各年龄段抽取的个数依次为125/5，280/5，95/5，即25，56，19。
    
    正负样本不平衡处理办法:
        正样本 >> 负样本,且量都很大 => 下采样
        正样本 >> 负样本,量不大 =>
	    1.采集数据
	    2.oversampling(例如:图像识别中的镜像和旋转)
	    3.修改损失函数/loss function

数据与特征处理:
     数值型:
         1.幅度调整/归一化 python的preprocessing.MinMaxScaler()可以进行最大最小归一化   使用preprocessing.scale(x)进行缩放时,均值为0,标准差1.
	 2.Log等变化
	 3.统计值 max min mean std
	     series = pd.Series(np.random.randn(500))
	     series.describe(percentiles=[.05,.25,.75,.95]) #输出count,mean,std,min,5%,25%,50%,75%,95%,max
	 4.离散化
	     可以使用cut()和qcut()
	 5.Hash分桶
	 6.每个类别下对应的变量统计值histogram(分布状况)
	 7.试试 数值型 => 类别型
         
         
     类别型:
         1.ont-hot编码 pd.get_dummies()
	 2.哑变量
	 3.hash与聚类处理
	     hash技巧:
	     Histogram映射:
	 4.统计每个类别变量下各个target比例,转成数值型

     时间型:
         1.连续型
	     a)持续时间(单页浏览时长)
	     b)间隔时间(上次购买/点击离现在的时间)
	 2.离散型
	     a)一天中哪个时间段(hour_0-23)
	     b)一周中星期几(week_monday)
	     c)一年中哪个星期
	     d)一年中哪个季度
	     e)工作日/周末

可以使用GBDT进行特征组合
组合出来的特征和原始特征一同放入模型中进行训练



特征选择:三种方法:过滤 包裹 嵌入
    原因:
        1.冗余:部分特征的相关度太高,消耗计算性能.
	2.噪声:部分特征是对预测结果有负影响

特征选择 vs 降维
    1.前者只是剔除了原本特征中和结果预测关系不大的,后者做特征的计算组合构成新特征
    2.SVD或PCA缺失也能结果一定的高维度问题

特征选择方式:
过滤型:
    1.评估单个特征和结果值之间的相关程度,排序留下Top相关的特征部分.
    2.Pearson相关系数   互信息  距离相关度
    3.缺点:没有考虑到特征之间的关联作用,可能把游泳的关联特征误踢掉.

包裹型:
    1.把特征选择看作一个特征子集搜索问题,筛选各种特征子集, 用模型评估效果.
    2.典型的包裹型算法为"递归特征删除算法",RFE(Recursive feature elimination)
    3.LR如和做这个事情呢?
        1.用全量特征跑一个模型
	2.根据线性模型的系数(体现相关性),删除5%-10%的弱特征,观察准确率/auc的变化
	3.逐步进行,直至准确率/auc出现大幅度的下滑,停止.
嵌入型:
    1.根据模型来分析特征的重要性
    2.最常见的方式为 用L1正则化方式来做特征选择
    3.举个例子,最早在电商用LR座CTR预估,在3-5亿维的系数特征上用L1正则化的LR模型,剩余2-3千万的feature,意味着其他的feature重要读不高.

==================================================================================================================
连续值 用C4.5分段,然后二值化
==================================================================================================================


